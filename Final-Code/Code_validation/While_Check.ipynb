{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Error encountered when serializing while_context.\n",
      "Type is unsupported, or the types of the items don't match field type in CollectionDef.\n",
      "'NoneType' object has no attribute 'name'\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "[[ -9.72272828e-03]\n",
      " [  1.99660659e+00]\n",
      " [  3.99027729e+00]\n",
      " [  5.99027729e+00]\n",
      " [  7.99189663e+00]\n",
      " [  9.99660683e+00]\n",
      " [  1.20066261e+01]\n",
      " [  1.40066261e+01]\n",
      " [  1.59993162e+01]]\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "[[ 16.00154114]\n",
      " [ 18.02223969]\n",
      " [ 19.99732018]\n",
      " [ 21.9932003 ]\n",
      " [ 24.02223969]\n",
      " [ 25.9932003 ]\n",
      " [ 27.99959946]\n",
      " [ 29.99959946]\n",
      " [ 32.00499725]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import mock, collections\n",
    "from tensorflow.python.util import nest\n",
    "from keras import backend as K\n",
    "count = 9\n",
    "batch = 2\n",
    "logs_path = '/Users/kalyanb/PycharmProjects/MetaLearning/while_loop_log/'\n",
    "np.random.seed(7)\n",
    "def _wrap_variable_creation(func, custom_getter):\n",
    "  \"\"\"Provides a custom getter for all variable creations.\"\"\"\n",
    "  original_get_variable = tf.get_variable\n",
    "  def custom_get_variable(*args, **kwargs):\n",
    "    if hasattr(kwargs, \"custom_getter\"):\n",
    "      raise AttributeError(\"Custom getters are not supported for optimizee \"\n",
    "                           \"variables.\")\n",
    "    return original_get_variable(*args, custom_getter=custom_getter, **kwargs)\n",
    "\n",
    "  # Mock the get_variable method.\n",
    "  with mock.patch(\"tensorflow.get_variable\", custom_get_variable):\n",
    "    return func()\n",
    "\n",
    "\n",
    "def _get_variables(func):\n",
    "\n",
    "  variables = []\n",
    "  constants = []\n",
    "\n",
    "  def custom_getter(getter, name, **kwargs):\n",
    "    trainable = kwargs[\"trainable\"]\n",
    "    kwargs[\"trainable\"] = False\n",
    "    variable = getter(name, **kwargs)\n",
    "    if trainable:\n",
    "      variables.append(variable)\n",
    "    else:\n",
    "      constants.append(variable)\n",
    "    return variable\n",
    "\n",
    "  _wrap_variable_creation(func, custom_getter)\n",
    "\n",
    "  return variables, constants\n",
    "\n",
    "\n",
    "def _make_with_custom_variables(func, variables):\n",
    "\n",
    "  variables = collections.deque(variables)\n",
    "\n",
    "  def custom_getter(getter, name, **kwargs):\n",
    "    if kwargs[\"trainable\"]:\n",
    "      return variables.popleft()\n",
    "    else:\n",
    "      kwargs[\"reuse\"] = True\n",
    "      return getter(name, **kwargs)\n",
    "\n",
    "  return _wrap_variable_creation(func, custom_getter)\n",
    "\n",
    "\n",
    "def prob():\n",
    "    da = tf.random_normal(shape=[10,],dtype=tf.float32,stddev=0.01)\n",
    "    with tf.name_scope(\"Loss\"):\n",
    "        def loss():\n",
    "            with tf.name_scope(\"index\"):\n",
    "                index = tf.random_uniform([1], 0, 10, tf.int64)\n",
    "            with tf.variable_scope(\"var\",reuse=tf.AUTO_REUSE):\n",
    "                x1 = tf.get_variable(\"x1\",shape=[1],dtype=tf.float32,initializer=tf.zeros_initializer)\n",
    "            d = tf.gather(da,index)\n",
    "            return tf.add(x1,d)\n",
    "    with tf.name_scope(\"Aux_Loss\"):\n",
    "        def aux_loss():\n",
    "            with tf.name_scope(\"index\"):\n",
    "                index = tf.random_uniform([1], 0, 10, tf.int64)\n",
    "            with tf.variable_scope(\"aux_var\",reuse=tf.AUTO_REUSE):\n",
    "                v = tf.get_variable(\"v\",shape=[1],dtype=tf.float32,initializer=tf.zeros_initializer)\n",
    "                x2 = tf.get_variable(\"x2\",shape=[1],dtype=tf.float32,initializer=tf.zeros_initializer)\n",
    "            d = tf.gather(da,index)\n",
    "            return tf.add(x2,tf.add(v,d))\n",
    "    return collections.OrderedDict([('loss',loss),('aux_loss',aux_loss)])\n",
    "\n",
    "\n",
    "def test(prob):\n",
    "    optvar = [_get_variables(a)[0] for a in prob.values()]\n",
    "    num = nest.flatten([0,[len(a) for a in optvar]])\n",
    "\n",
    "    def time_step(t,f_array,f_array_loss,f_array_aux,x):\n",
    "        losstot = [_make_with_custom_variables(a, x[num[b]:num[b]+num[b+1]]) \n",
    "                   for a,b in zip(prob.values(),range(len(num)-1))]\n",
    "        fx_loss = losstot[0]\n",
    "        f_array_loss = f_array_loss.write(t,fx_loss)\n",
    "        fx_aux =losstot[1]\n",
    "        f_array_aux = f_array_aux.write(t, fx_aux)\n",
    "        fx = sum(losstot[a] for a in range(len(losstot)))\n",
    "        f_array = f_array.write(t, fx)\n",
    "        x_n = [a+1 for a in x]\n",
    "        t_n = t+1\n",
    "        return t_n,f_array,f_array_loss,f_array_aux,x_n\n",
    "\n",
    "    fx_array = tf.TensorArray(tf.float32, size=count,\n",
    "                              clear_after_read=False)\n",
    "    fx_array_loss = tf.TensorArray(tf.float32, size=count,\n",
    "                              clear_after_read=False)\n",
    "    fx_array_aux = tf.TensorArray(tf.float32, size=count,\n",
    "                                   clear_after_read=False)\n",
    "    t_f, fx_array, fx_array_loss, fx_array_aux, x_final = tf.while_loop(\n",
    "        cond=lambda t, *_: t < count-1,\n",
    "        body=time_step,\n",
    "        loop_vars=(0, fx_array, fx_array_loss, fx_array_aux, nest.flatten(optvar)),\n",
    "        parallel_iterations=1,\n",
    "        swap_memory=True,\n",
    "        name=\"loop\")\n",
    "    finallosstot = [_make_with_custom_variables(a,x_final[num[b]:num[b]+num[b+1]]) \n",
    "                    for a,b in zip(prob.values(),range(len(num)-1))]\n",
    "    fx_final = sum(finallosstot[a] for a in range(len(finallosstot)))\n",
    "    fx_final_loss = finallosstot[0]\n",
    "    fx_final_aux = finallosstot[1]\n",
    "    with tf.name_scope('WriteFinalAux'):\n",
    "        fx_array_aux = fx_array_aux.write(count-1,fx_final_aux)\n",
    "    with tf.name_scope('WriteFinalLoss'):\n",
    "        fx_array_loss = fx_array_loss.write(count-1,fx_final_loss)\n",
    "    with tf.name_scope(\"WriteFinal\"):\n",
    "        fx_array = fx_array.write(count-1,fx_final)\n",
    "    with tf.name_scope(\"ArrayInfo\"):\n",
    "        array_f= fx_array.stack()\n",
    "    with tf.name_scope(\"ArrayInfoLoss\"):\n",
    "        array_f_loss= fx_array_loss.stack()\n",
    "    with tf.name_scope(\"ArrayInfoAux\"):\n",
    "        array_f_aux= fx_array_aux.stack()\n",
    "    with tf.name_scope(\"Reset\"):\n",
    "        reset = [tf.variables_initializer(nest.flatten(optvar)),\n",
    "                 fx_array.close(),fx_array_aux.close(),fx_array_loss.close()]\n",
    "    with tf.name_scope(\"Update\"):\n",
    "        update = [tf.assign(r,v) for r,v in zip(nest.flatten(optvar),x_final)]\n",
    "\n",
    "    return update,reset, array_f, t_f, fx_final, x_final, array_f_loss, array_f_aux\n",
    "\n",
    "prob = prob()\n",
    "update, reset, array_f, t_f, fx_final, x_final, array_f_loss, array_f_aux = test(prob)\n",
    "with tf.Session() as sess:\n",
    "    graph_writer = tf.summary.FileWriter(logs_path, sess.graph)\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    sess.run(reset)\n",
    "    fall = []\n",
    "    for i in range(2):\n",
    "        t,xf,f,f_loss,f_aux,_ = sess.run([t_f,x_final,array_f, array_f_loss, array_f_aux, update])\n",
    "        print(f - (f_loss + f_aux))\n",
    "        print(f_aux)\n",
    "        fall.append(f)\n",
    "    graph_writer.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
