\chapter{Overview of bilevel programming}
\label{chapter:2}


\section{Single-Objective Bilevel Optimization}
\label{sing_obj_bilevel_lite}

A single-objective optimization problem can be mathematically defined as shown in Equation~\ref{eq:single_level}.

\begin{equation}
\begin{array}{lr}
\underset{\mathbf{x}}{\text{Minimize}}\hspace{2mm} F(\mathbf{x}), \hspace{2mm} \text{where}\hspace{2mm}{\mathbf{x} \in \ \mathbb{X}}\\
  \hspace{4mm}\text{S.t.}\hspace{9mm}G_k(\mathbf{x}) \le 0, k=1,...,q, \hspace{9mm}\\
\hspace{18mm}H_k(\mathbf{x}) = 0, k=1,...,r.\hspace{1mm}\\
\end{array}
\label{eq:single_level}
\end{equation}

Here, $F(\mathbf{x})$ is the objective function, $G$ is the set of $q$ inequality constraints, and $H$ is the set of $r$ equality constraints.  $\mathbf{x}$ is a vector of $n$ design variables in the domain $\mathbf{X}$~(defined using upper and lower bounds of each variable), where $F(\mathbf{x}) \in \mathbb{R} \forall \mathbf{x}$. Without loss of generality, the objective function is always considered to be minimized~(unless stated otherwise) in this thesis. A minimization problem can be converted to a maximization problem by simply switching the sign of the function, which is commonly referred to as the \textit{duality principle}. 

A single-objective bilevel optimization problem is an extended version of the problem described above, in which the optimization has to be performed at two levels, upper and lower. Each level has its own variables, objectives and constraints. The subscript $u$ will be henceforth used to denote attributes of the upper level problem, whereas subscript $l$ will be used for the lower level problem. For a given upper level vector $\mathbf{x}_u$, the evaluation of upper level function is valid/feasible \textit{only if} the $\mathbf{x}_l$ for the corresponding lower level problem (with $\mathbf{x}_u$ held constant) is optimum. This critical relation leads to the nested nature of the bilevel problem. Mathematically, a bilevel problem can be represented as shown in Equation~\ref{bi_level}.


\begin{equation}
\begin{array}{lr}
 \underset{\mathbf{x}_u}{\text{Minimize}}\hspace{2mm} F_u(\mathbf{x}_u, \mathbf{ x}_l), \hspace{2mm} \\ 
 \hspace{4mm}\text{S.t.}\hspace{9mm}G_k(\mathbf{x}_u, \mathbf{ x}_l) \le 0, k=1,\ldots,q_u, \hspace{2mm}\\
\hspace{18mm}H_k(\mathbf{x}_u, \mathbf{ x}_l) = 0, k=1,\ldots,r_u, \hspace{2mm}\\
\text{ }\\
\hspace{9mm} \underset{\mathbf{x}_l}{\text{Minimize}}\hspace{2mm} f_l(\mathbf{x}_u, \mathbf{ x}_l), \\
 \hspace{9mm} \hspace{4mm}\text{S.t.}\hspace{9mm}g_k(\mathbf{x}_u, \mathbf{ x}_l) \le 0, k=1,\ldots,q_l, \hspace{2mm}\\
\hspace{9mm}\hspace{18mm}h_k(\mathbf{x}_u, \mathbf{ x}_l) = 0, k=1,\ldots,r_l, \hspace{1mm}\\
\hspace{9mm} \text {where}\hspace{2mm}{\mathbf{x}_u \in \mathbb{X}_u}, \hspace{2mm}{\mathbf{x}_l \in \ \mathbb{X}_l}\\
\end{array}
\label{bi_level}
\end{equation}


In Equation.~\ref{bi_level}, the upper level objective function is $F_u(\mathbf{x}_u, \mathbf{ x}_l)$ and the lower level objective function is $f_l(\mathbf{x}_u, \mathbf{ x}_l)$. The vectors $\mathbf{x}_u$ and $\mathbf{x}_l$ denote the upper level variables~(in domain  $\mathbb{X}_u$) and lower level variables~(in domain $\mathbb{X}_l$) respectively. $G$ and $H$ are the sets representing $q_u$ inequality and $r_u$ equality constraints for upper level problem. Similarly, there are $q_l$ inequality constraints in $g$ and $r_l$  equality constraints in $h$ for the lower level problem. 

For the lower level problem, $\mathbf{x}_u$ acts as a fixed parameter. Corresponding to each $\mathbf{x}_u$, there is a lower level optimum (=$\mathbf{x}^*_l$), which is used to evaluate the upper level objective function $F_u(\mathbf{x}_u, \mathbf{ x}_l)$. The overall goal is to optimize the upper level~(``leader'') function subject to lower level optimality.  
 
A number of the methods reported in the field of evolutionary bilevel optimization operate using a nested mode which, evidently, is a direct way of addressing the problem. By a nested approach, it is meant that to evaluate upper level objective for a given set of upper level variables $\mathbf{x}_u$, the lower level problem is solved using a suitable optimizer. If the lower level optimizer is able to obtain a optimal~(feasible) solution $\mathbf{x}_l^*$ of the lower level problem, then the set \{$\mathbf{x}_u,\mathbf{x}^*_l$\} is used to evaluate the upper level objective and constraints. This forms an individual evaluation for an optimizer solving the upper level problem. If the lower level optimization doesn't return a feasible solution to the lower level problem, the upper level solution is discarded. There have also been several efforts towards developing non-nested techniques, where the optimality of the lower level problem is posed as a complementary constraint to the upper level problem. This approach has been more commonly used in classical methods, effectively converting the bilevel problem to a single-level problem. 

The prominent approaches reported in the literature to deal with bilevel optimization problems are briefly discussed in the following subsections. 



\subsection{Classical Approaches}
\label{classical_all}

The term \textit{classical approach} in the present context refers to the methods that either use analytical/gradient information via calculus, or may rely on derivative-free schemes such as branch and bound. They are usually straightforward to implement and require fairly low computational resources. However, their application is limited as they require assumptions on the nature of the objective and/or constraint functions, such as continuity, differentiability, linear/quadratic form etc. Additionally, except for some cases (e.g. linear and convex problems), they identify local optimum as opposed to global search methods, and hence are not suitable for multimodal problems. 

For linear bilevel optimization problems, a number of classical approaches have been suggested in the literature. Some of these include simplex method~\cite{dempe1987simple,onal1993modified}, branch and bound~\cite{bard1982explicit,hansen1992new,bard1990branch}, descent methods~\cite{vicente1994descent,savard1994steepest}, adaptive tabu search~\cite{gendreau1996hybrid} and penalty based approach~\cite{white1993penalty,aiyoshi1984solution,aiyoshi1981hierarchical,ishizuka1992double}. The choice of the algorithm is primarily dictated by the characteristics of the problem, such as the form of the objective function~(convex/non-convex), number of decision variables at upper and lower level and the type of constraints. The method presented in~\cite{dempe1987simple} used a simplex method with additional rules to handle slack variables. It operates on a ``full description'' of the feasible set, obtained using the concept of active constraints and sub-gradients. However, it needs an interior feasible starting point. In contrast, branch and bound method proposed by~\cite{bard1982explicit} can be applied to solve non-convex problems and non-linear problems. However, its complexity grows exponentially with the number of variables, as it is an exhaustive search technique. Steepest descent direction~\cite{savard1994steepest} and derivative based approach~\cite{kolstad1990derivative} are computationally faster, but may often converge to local optimum. Additionally, for non-differentiable or non-smooth functions, numerical gradients are not accurate and can often mislead the search. In~\cite{colson2005trust}, an approximation of non-linear bilevel mathematical program was used in conjunction with trust-region based methods. A derivation of generalized conditions for a local optimum in the context of bilevel programming problem appear in \cite{falk1995bilevel}. Two algorithms were proposed to solve the problems under these assumptions, namely trust region bundle method with the sub-gradient information of the lower level problems, and hybrid algorithm combining bundle methods and quasi Newton methods. The approach was tested on two nonlinear problems. A tabu search based algorithm was proposed by~\cite{rajesh2003tabu}, and its performance was demonstrated on a set of nine linear/quadratic test problems.  The algorithm proposed in~\cite{lai1996hierarchical} established the relationship in the leader -follower hierarchical model in classical 

\subsection{Complementary constraint approaches}
\label{comple_all}
Some of the approaches, predominantly classical, attempt to reformulate the original bilevel optimization problem as a single-level problem, using an additional \textit{complementary} constraint. Karush-Kuhn-Tucker~(KKT) condition is one such analytical condition that can be used to ensure local optimality at a given point and thus has been extensively used as complementary constraint. 

For linear bilevel programming, the complementary constraint approach has been used with branch and bound method~\cite{hansen1992new}, penalty approach~\cite{lv2007penalty} and mixed integer programming~\cite{saharidis2009resolution}. The approach converts a linear bilevel programming problem into a linear/non-linear problem by imposing the KKT conditions as additional constraints. Problems with up to 250 upper level variables, 150 linear constraints, and up to 150 lower level variables were solved using the technique in ~\cite{hansen1992new}. For non-linear problems, KKT was used with \emph{exact} and \emph{inexact} penalty function approaches in~\cite{marcotte1996exact}. In a penalty function based approach, a constrained problem is transformed into an unconstrained problem by adding a penalty term to the objective based on the amount of constraint violation. A combination of duality theory and KKT optimality conditions was used in ~\cite{jenabi2013bi} to convert a bilevel problem~( concerning electric power networks) into mixed integer linear and non-linear programming problems. In ~\cite{herskovits2000contact}, a contact shape optimization problem was formulated as a bilevel programming problem. They formulated and used alternative optimality conditions~(in lieu of KKT) as the complementary constraints for this problem. In \cite{sahin1998dual}, a simulated annealing~(SA) based algorithm was proposed to solve bilevel optimization problem. Their key idea was to stochastically relax or ``fuzzify'' the constraints that represent the lower level problem during the search. This relaxation is controlled by a parameter~($T_{in}$), whereas another parameter~($T_{out}$) is used for the annealing at the upper level; thus resulting in a ``dual-temperature'' SA. The approach was applied to finding a safe process layout for a chemical plant. \cite{carrion2009bilevel} formulated a medium-term decision making problem by a power retailer as a bilevel programming problem. To solve the problem, they transformed the bilevel problem to a single-level mixed integer problem using KKT optimality conditions, and converted the nonliterary in the resulting problem to linear equivalents using well-known integer algebra results. \cite{ye2006constraint} extended well known constraint qualifications~(Abadie, Zungwill, Kuhn-Tucker)  used for nonlinear programming to bilevel programming problems. Based on these constraint qualifications, they proposed KKT-like optimality conditions which could be used as constraints for the reformulated problem. Subsequently, in \cite{ye2010new}, classical and value function approaches were combined to derive new necessary optimality conditions for a bilevel programming problems. 


It is important to take note that KKT condition~(or other similar optimality conditions)  provide necessary and sufficient condition for the optimum only for the linear and convex type problems. However, KKT cannot be applied to discontinuous and non-convex functions~\cite{sahin1998dual}, which has prompted the use of other optimality conditions discussed in the above works. 


\subsection{Evolutionary Approaches}
\label{population_all}

In recent decades, population based metaheuristic optimization methods have gained popularity for a number of reasons. They are global search methods and do not require specific conditions on the mathematical form of the objective functions and are inherently suited to solve multi-objective problems. Such algorithms can also be readily implemented in parallel, which is especially advantageous for cases where evaluation of objective/constraint functions is significantly expensive compared to algorithmic operators. On the other hand, it is important to highlight that they cannot guarantee optimality. In the bilevel model, if true optimum of lower level is not achieved, then the solution is considered infeasible at upper level. This is one of the key limitations of using metaheuristic methods for lower level optimization problems, but several studies in literature have demonstrated their ability to achieve near optimal solutions (for both single and bilevel optimization problems). Besides, in some cases analytical expressions or their properties involved in the objective/constraints are unknown, e.g. when evaluation is result of a numerical analysis such as Finite Element Analysis~(FEA), Computational Fluid Dynamics~(CFD), or a physical experiment. In such cases the classical techniques may not be applicable, in which case heuristics/metaheuristics remain the only alternative. The number of function evaluations used for optimization can be one of the concerns while using metaheuristics. Population based methods in particular tend to evaluate large number of solutions during the course of the search. This may not be affordable if the function evaluation is computationally expensive, as it would result in significant run-time for overall optimization exercise. Parallel computing can compensate for this issue where possible, and often a trade-off has to be made to get the best out of the available resources. Some of the population based methods used in the context of bilevel optimization are outlined below. 

A genetic algorithm based method called GABBA was introduced in \cite{mathieu1994genetic}. The approach utilized a mutation strategy specific to bilevel problems, and demonstrated improvements in accuracy compared to grid search~\cite{bard1983efficient}. In \cite{wang2007adaptive}, linear bilevel problems were solved using an adaptive genetic programming approach. The approach incorporated intensification of search in the feasible space through evolutionary operators ensuring generation of feasible chromosomes. At the same time, probabilities of crossover and mutation were modified adaptively during the search. Yet another approach for linear problems was suggested in \cite{hejazi2002linear}, wherein a genetic algorithm was used to solve a transformed problem using KKT conditions. In \cite{oduguwa2002bi}, a Bilevel Genetic Algorithm~(BiGA), was proposed with a ``co-evolutionary operator'' to preserve the interactive nature of the decision making at two levels. An extension of this method was proposed in \cite{legillon2012cobra}, referred to as Coevolutionary Bi-level method using Repeated Algorithms (CoBRA). CoBRA incrementally improves two different sub-populations, each corresponding to one level, periodically exchanging information with each other. It was able to deal with linear bilevel optimization problems involving complex large-sized search spaces. In \cite{wang}, a genetic algorithm with self-adaptive penalty function was proposed to solve constrained bilevel optimization problems. The use of Particle Swarm Optimization~(PSO) has also been reported to solve bilevel linear programming problems in \cite{kuo2009application,halter2006bilevel} and generic bilevel linear programming problems in \cite{li2006hierarchical_new}. 

More recent methods have focused on non-linear bilevel optimization problems, which are less tractable due to relatively complex landscapes. Some of the notable contributions in this area are presented in \cite{sinha2014test,sinha2013efficient,sinha_improved_2014,lu2016finding,suryan2016handling,sinha2014bilevel_par}, focusing on both, the bilevel problem formulation and design of algorithms to solve them. They introduced a scalable set of bilevel test problems~(SMD series) incorporating different types of challenges such as non-linearity, multi-modality, and non-cooperation between upper and lower levels. Problems of the SMD series include eight unconstrained and four constrained single-objective problems. Results of basic Nested Bilevel Evolutionary Algorithm~(NBLEA) was presented for SMD1-SMD12 in \cite{sinha2014test}. The algorithm offered good convergence for unconstrained problems, but its performance on constrained problems was relatively inferior. In subsequent works~\cite{sinha2013efficient,sinha_improved_2014}, they proposed an improved evolutionary algorithm named Bilevel Evolutionary Algorithm on Quadratic Approximation~(BLEAQ). In BLEAQ, computational cost was reduced by estimating the approximate values of lower level optimum variables in lieu of exhaustive lower level search. Consequently the accuracy of the final solutions obtained depends on the ability of quadratic model to capture the relation between the lower level optimum and upper level variables accurately. In \cite{Angelobilevel}, a nested Bilevel Differential Evolution~(BIDE) based approach was proposed for single-objective problems. Extensive lower level search was performed for each upper level evaluation, resulting in competitive results, but at the expense of high numbers of function evaluations. 

\subsection{Hybrid Approaches}
For \emph{single-level} optimization problems, often global search methods (such as evolutionary algorithms) are used in conjunction with local search methods~(such as gradient search) to search for optimum solution efficiently. This \emph{hybrid} approach is referred to as memetic algorithm~\cite{moscato1989evolution}. For a review on memetic algorithms, the readers are referred to \cite{moscato2004memetic}. The advantages of using memetic algorithms have been reported in a number of prior studies including~\cite{singh2011performance} for conventional (single-level) optimization problems. When a bilevel problem is solved, parts of the strategy resemble single-level optimization, and a good technique for single-level optimization thus should have some potential of improving the performance for bilevel problems. However, there have been very few reports so far on application of memetic algorithms for the solution of bilevel optimization problems. Among these works, the approach has been to use a global optimizer at upper level and a local optimizer at lower level. \cite{Zhubilevel} introduced Differential Evolutionary~(DE) to solve leaders problems, while interior point method was used for solving follower problems. Similarly,in ~\cite{koh2013metaheuristic} DE was used to solve upper level problem and a gradient search for the lower level optimization. Although these schemes aid in reducing the number of function evaluations, there is a considerable likelihood of obtaining a local optimum at the lower level, which affects the upper level search.



\subsection{Approximation based approaches with EA}
\label{sec:approx_ea_ch2}
For conventional~(single-level) optimization problems, it is a common practice to use surrogate/approximate models to guide the search in order to solve a problem with lower number of true function evaluations. This methodology is particularly preferred if each true evaluation is computationally expensive. A review of the methods used for fitness approximation appears in \cite{wang_review_2007} and a survey on the use of fitness approximation in the context of evolutionary computation has been reported in \cite{jin2005csf}. However, surrogate models have been rarely employed in the domain of bilevel optimization so far. To the author's knowledge, the only published works that use approximate models during the evolutionary bilevel search are the following:

\noindent\textit{Modified NBLEA:} Nested Bilevel Evolutionary Algorithm~(NBLEA) was proposed in \cite{sinha2014test} as a basic nested algorithm in which each of the levels are optimized using an EA. The use of EA at both levels inherently consumed a large number of function evaluations. Therefore the algorithm was subsequently modified and the changes are reflected in the user documentation for its code \cite{sinha2014bilevel}. In the modified algorithm, the lower level problem is first attempted to be modelled as a quadratic programming problem, i.e., quadratic objective function with linear constraints. If the model is built successfully, then a quadratic programming approach is used to solve the (approximate) problem and the solution is accepted as optimal if the true evaluation at the point is close to the approximate optimum. As a result, the function evaluations were significantly reduced if the lower level problems are quadratic in nature~(e.g. \cite{Angelo2013}). However, for more generic non-linear problems where the quadratic programming is not applicable, the number of function evaluations remain relatively high.

\noindent\textit{BLEAQ:} An efficient bilevel evolutionary algorithm based on quadratic approximations~(BLEAQ) was proposed in \cite{sinha2013efficient}. In this approach, the optimum lower level variable values were approximated as a function of the upper level variables. The model used for fitting was again quadratic. If the quadratic fit was successful, then the optimum lower level variable values were approximated instead of evaluated~(through lower level optimization), saving on significant number of lower level evaluations. An extension of the method was proposed in \cite{sinha_improved_2014}, where the search was further enhanced using archiving and local search at upper level.

\noindent\textit{Surrogate assisted BIDE:} The Bilevel Differential Evolution~(BIDE) approach presented in \cite{Angelo2013} used an exhaustive DE search at both levels, resulting in a good performance but extremely high number of evaluations. In order to reduce this effort, a surrogate model was built between the upper level variables and the corresponding lower level optimum values. The concept is along the same lines as used in BLEAQ, but the type of surrogate model used in this case was the Similarity-Based Surrogate Model~(SBSM) based on $k$ nearest neighbours The choice of using a true evaluation~(lower level optimization) or a surrogate model to identify the lower level optimum was determined through a probability $\beta$. As the probability of using the surrogate model~($\beta$) was increased, it was observed that the performance of the algorithm deteriorated. For $\beta\geq 0.5$ the results were observed to deviate significantly from the true optimum values. 



\section{Multi-Follower Bilevel Problems}

In practice, there may also exist more than one followers in a bilevel problem, which is typically referred to
as bilevel multi-follower~(BLMF) problem. An example is given in \cite{lu2006bilevel} where the
government acts as the leader in a land-use planning problem, with an objective of achieving maximum
returns through suitable agricultural policies. On the other hand, at the lower level there could be
several other groups such as farmers, conservationists, aboriginals etc. with the their own
objectives, constituting the corresponding follower problems. The followers could be
\emph{dependent}, which means they share some common variables, or \emph{independent}, where their
variables are mutually exclusive~\cite{calvete2007linear,shi2005k}. Consequently, dependent
followers can affect the leader's as well as each others decision, while the independent followers
can only affect the leader's decision. Another terminology is also used in the literature
\cite{lu2006bilevel} where the followers are considered uncooperative, cooperative or partial
cooperative depending on whether they share none, all or some of their variables. Dependent follower
problems are particularly challenging since the optimality condition needs to be satisfied for each
follower in conjunction with others. The solution(s) satisfying this criteria are characterized by
so called Stackelberg-Nash equilibrium~\cite{liu1998stackelberg,angelo2015}. This adds further
computational expense to the problem, since it might require a few iterations of optimization among
the followers to achieve an equilibrium. For certain upper level solutions, such equilibrium
solutions may not exist at lower level~\cite{liu1998stackelberg}. 

In this thesis, only single-objective problems with one leader at upper level and two followers at the lower level are considered. Mathematically, the given problem can be stated as shown in Equation~\ref{eq:bilevel}. In the equation, the subscript $u$ is used to denote attributes of the upper level problem, whereas subscripts $l$ and $z$ are used for the first and second followers, respectively. The optimum solutions of the lower level problems form the feasible space of the upper level problem, i.e., for a given upper level vector $\mathbf{x}_u$, the evaluation of upper level function is valid/feasible \textit{only if} the $\mathbf{x}_l$ and $\mathbf{x}_z$  for the corresponding lower level problems (with $\mathbf{x}_u$ held constant) are also optimum~(termed as Stackelberg-Nash equilibrium). 


\begin{equation}
\begin{array}{lr} 
\underset{\mathbf{x}_u}{\text{Minimize}}\hspace{2mm} F(\mathbf{x}_u, \mathbf{ x}_l, \mathbf{ x}_z), \hspace{2mm} \\ 
\hspace{4mm}\text{S.t.}\hspace{9mm}G_k(\mathbf{x}_u, \mathbf{ x}_l, \mathbf{ x}_z) \le 0, k=1,\ldots,q_u, \hspace{2mm}\\
\hspace{18mm}H_k(\mathbf{x}_u, \mathbf{ x}_l, \mathbf{ x}_z) = 0, k=1,\ldots,r_u, \hspace{2mm}\\
\quad \underset{\mathbf{x}_l}{\text{Minimize}}\hspace{2mm} f_l(\mathbf{x}_u, \mathbf{ x}_l, \mathbf{ x}_z), \\
\quad\hspace{4mm}\text{S.t.}\hspace{9mm}gl_k(\mathbf{x}_u, \mathbf{ x}_l, \mathbf{ x}_z) \le 0, k=1,\ldots,q_l, \hspace{2mm}\\
\quad\hspace{18mm}hl_k(\mathbf{x}_u, \mathbf{ x}_l, \mathbf{ x}_z) = 0, k=1,\ldots,r_l. \hspace{1mm}\\
\quad\underset{\mathbf{x}_z} {\text{Minimize}}\hspace{2mm} f_z(\mathbf{x}_u, \mathbf{ x}_l, \mathbf{ x}_z), \\
\quad \hspace{4mm}\text{S.t.}\hspace{9mm}gz_k(\mathbf{x}_u, \mathbf{ x}_l, \mathbf{ x}_z) \le 0, k=1,\ldots,q_z, \hspace{2mm}\\
\quad\hspace{18mm}hz_k(\mathbf{x}_u, \mathbf{ x}_l, \mathbf{ x}_z) = 0, k=1,\ldots,r_z. \hspace{1mm}\\
\text {where},\hspace{2mm}{\mathbf{x}_u \in \mathbb{X}_u}, \hspace{2mm}{\mathbf{x}_l \in \ \mathbb{X}_l}, \hspace{2mm}{\mathbf{x}_z \in \ \mathbb{X}_z}
\end{array}
\label{eq:bilevel}
\end{equation}


In Equation~\ref{eq:bilevel}, the vector $\mathbf{x}_u$ denotes the upper level variables~(in domain
$\mathbb{X}_u$) and $\mathbf{x}_l$ and $\mathbf{x}_z$ denote lower level variables~(in domain
$\mathbb{X}_l$ and $\mathbb{X}_z$) respectively. The upper objective function is $F(\mathbf{x}_u, \mathbf{ x}_l, \mathbf{ x}_z)$ and the lower level objective functions are $f_l(\mathbf{x}_u, \mathbf{ x}_l, \mathbf{ x}_z)$ and
$f_z(\mathbf{x}_u, \mathbf{ x}_l, \mathbf{ x}_z)$. $G$ and $H$ are the sets of $q_u$ inequality and $r_u$ equality
constraints for upper level problem. Similarly, there are $q_l$ inequality constraints in $gl$ and
$r_l$ equality constraints in $hl$ for lower level first follower. For the second follower these are
denoted by $gz$ and $hz$ respectively. The upper level objective function is optimized with respect
to $\mathbf{x}_u$ where $\mathbf{x}_l$ and $\mathbf{x}_z$ act as a fixed parameters. First
lower level function is optimized with respect to $\mathbf{x}_l$ using $\mathbf{x}_u$ and
$\mathbf{x}_z$ as fixed parameters. Similarly, the second lower level function is optimized with
respect to $\mathbf{x}_z$ using $\mathbf{x}_u$ and $\mathbf{x}_l$ as fixed parameters.

\subsection*{Stackelberg-Nash Equilibrium}

For the upper level evaluation to be valid, the lower level variables~(in this case $\mathbf{x}_l$
and $\mathbf{x}_z$) must be set at values such that both the lower level functions are at their
optimum for the given $\mathbf{x}_u$. This condition is referred to as Stackelberg-Nash Equilibrium,
or sometimes simply as Nash Equilibrium~(NE)~\cite{nash1951non,angelo2015}. Thus the upper level
objective function can in fact be written as $F(\mathbf{x}_u, \mathbf{ x}^*_l, \mathbf{ x}^*_z)$, where $\mathbf{x}^*_l$
and $\mathbf{x}_z^*$ are NE solutions. Mathematically, for two followers, the conditions given in
Equation~\ref{eq:nash} must be simultaneously satisfied, along with the respective constraints.

\begin{equation} \begin{aligned} f_l(\mathbf{x}_u, \mathbf{ x}^*_l, \mathbf{ x}^*_z) & \leq f_l(\mathbf{x}_u, \mathbf{ x}_l, \mathbf{ x}^*_z) \forall \mathbf{x}_l\in \mathbb{X}_l\\ f_l(\mathbf{x}_u, \mathbf{ x}^*_l, \mathbf{ x}^*_z) & \leq
f_z(\mathbf{x}_u, \mathbf{ x}^*_l, \mathbf{ x}_z) \forall \mathbf{x}_z\in \mathbb{X}_z\\ \end{aligned} \label{eq:nash}
\end{equation}

As discussed in \cite{liu1998stackelberg}, NE can be calculated in three ways: (a)analytically; (b)
by iterating between the follower optimization problems; and (c) by formulating an error function
and using a global optimizer to minimize it to zero. Of these, method (a) can guarantee the solution
if it exists, but can be applied for very limited number of cases, whereas (b) and (c) take longer
and cannot guarantee a solution, but are more widely applicable. In practice, (b) is more commonly
used, which is also adopted in the approach presented here.

\subsection{Multi-Follower Bilevel Approaches}
\label{multi_follower_ch_2}

Based on the above two types of
BLMF problems, the existing approaches in literature to solve BLMF could be broadly divided into two
groups -- first that focuses on independent follower problems and second that focuses on dependent
follower problems:

\begin{itemize} \item {\it Independent BLMF: } The independent follower problems have been explored
in \cite{shi2005k,calvete2007linear,lu2006bilevel}, where no variables are shared among the
followers. In \cite{shi2005k}, the \emph{Kth-Best} approach~\cite{candler1982linear} for linear
bilevel problems was extended to solve independent multi-follower problems. The approach finds the
global optimum of linear BLP problem by enumerating the extreme points of the constraint
region~\cite{shi2005k}. In \cite{calvete2007linear}, it was proven that the linear independent BLMF
problems could be reformulated to have a single follower at the lower level by using a suitable
objective function and constraint region. It was also noted that the approach presented in
\cite{shi2005k} resulted in misconstruction's of inducible region. Similar approach of transforming
the independent BLMF into single follower problem was also adopted in ~\cite{arora20090} to solve
0-1 bilevel fractional programming problem. A generic bilevel framework was presented in
\cite{lu2006bilevel} which discusses nine different possible cases of BLMF based on cooperation
between the followers. Thereafter, they extended the Kuhn-Tucker approach for identifying optimal
solutions for the uncooperative~(independent) decision model.

\item {\it Dependent BLMF: } Some of the studies have also focused on dependent BLMF problems, such
as those reported in \cite{liu1998stackelberg,Qian2000,angelo2015}. In \cite{Qian2000}, the BLMF
problem is transformed into single follower problem and solved using branch and bound technique. The
approach considers linear BLMF problems only. Genetic algorithm is incorporated
in~\cite{liu1998stackelberg} to solve problems with both independent and dependent followers. The
algorithm is able to handle non-linear problems, but requires excessively high number of function
evaluations to reach the optimum. More recently, a differential evolutionary based approach is used
to solve dependent multiple followers problems in~\cite{angelo2015}. The algorithm shows competitive
performance on a number of dependent BLMF problems, but also uses relatively large number of
function evaluations.

\end{itemize}


\section{Multi-objective Bilevel Optimization}
\label{multi_obj_ch_2}


Following similar notations as in Section~\ref{sing_obj_bilevel_lite}, a generic multi-objective bilevel problem can be mathematically represented as shown in Equation~\ref{bi_level_def}.

%%--Modify consistently

\begin{equation}
\begin{array}{lr}
 \underset{\mathbf{x}_u}{\text{Minimize}}\hspace{2mm} F_1(\mathbf{x}_u, \mathbf{ x}_l),F_2(\mathbf{x}_u, \mathbf{ x}_l),\dots, F_{M_u}(\mathbf{x}_u, \mathbf{ x}_l), \hspace{2mm} \\ 
 \hspace{4mm}\text{S.t.}\hspace{9mm}G_k(\mathbf{x}_u, \mathbf{ x}_l) \le 0, k=1,\ldots,q_u, \hspace{2mm}\\
\hspace{18mm}H_k(\mathbf{x}_u, \mathbf{ x}_l) = 0, k=1,\ldots,r_u, \hspace{2mm}\\
\text{ }\\
\hspace{9mm} \underset{\mathbf{x}_l}{\text{Minimize}}\hspace{2mm} f_1(\mathbf{x}_u, \mathbf{ x}_l),f_2(\mathbf{x}_u, \mathbf{ x}_l),\ldots,f_{M_l}(\mathbf{x}_u, \mathbf{ x}_l), \\
 \hspace{9mm} \hspace{4mm}\text{S.t.}\hspace{9mm}g_k(\mathbf{x}_u, \mathbf{ x}_l) \le 0, k=1,\ldots,q_l, \hspace{2mm}\\
\hspace{9mm}\hspace{18mm}h_k(\mathbf{x}_u, \mathbf{ x}_l) = 0, k=1,\ldots,r_l, \hspace{1mm}\\
\hspace{9mm} \text {where}\hspace{2mm}{\mathbf{x}_u \in \mathbb{X}_u}, \hspace{2mm}{\mathbf{x}_l \in \ \mathbb{X}_l}\\
\end{array}
\label{bi_level_def}
\end{equation}



In Equation.~\ref{bi_level_def}, the upper objective (real-valued) functions are the $F_i(\mathbf{x}_u, \mathbf{ x}_l), i=1,2,\ldots, M_u$, and the lower level objective functions are the $f_i(\mathbf{x}_u, \mathbf{ x}_l), i=1,2,\ldots,M_l$. $\mathbf{x}_u$ is the vector of the $n_u$ upper level variables and $\mathbf{x}_l$ is the vector of the $n_l$ lower level variables. $G$ is the set of $q_u$ inequality constraints and $H$ is the set of $r_u$ equality constraint for the upper level problem. On the other hand, $g$ and $h$ have $q_l$ and $r_l$ number of inequality and equality constraints respectively for the lower level. For all the problems studied in this chapter, both levels are considered to be bi-objective, i.e, $M_u$=2  and $ M_l$=2.


\subsection{ Multi-Objective Bilevel Approaches}

Relatively few studies have focussed on multi-objective bilevel problems in the existing literature. In~\cite{eichfelder2010multiobjective}, an adaptive scalarization approach was used for problems with one variable at the upper level. The study in \cite{alves2012computing} considered a linear problem with two objectives at the upper level and one at lower level, and solved it using a multi-objective mixed-integer programming method. For the same class of problems, scalarization is used in \cite{calvete2010linear} at the upper level in order to solve the problem as a single-objective bilevel problem. A contrary case is studied in \cite{calvete2011linear}, where the upper level is single-objective while the lower level is bi-objective. For the case of interactive decision making between leader and follower, the problem was transformed into two separate multi-objective decision making problems in~\cite{shi1997interactive}. This work was further extended to include multiple interconnected decision makers at lower level in~\cite{shi2001model}. For linear bilevel multi-objective problems, mathematical programming was used in~\cite{nishizaki1999stackelberg} for three different situations based on anticipation of upper level decision maker - optimistic anticipation, pessimistic anticipation and anticipation based on past behavior of lower level decision maker. In~\cite{yin2002multiobjective}, a genetic algorithm is used to solve a transportation management and planning problems with two objectives at upper level and one at the lower level. 

Among the evolutionary algorithms to solve generic multi-objective bilevel problems, some notable works include~\cite{deb2009solve} and~\cite{carrasqueira2015bi}. Both of these algorithms divide the population at upper level into a number of sub-populations to solve lower level problems independently. While the former uses a non-dominated sorting algorithm as the base method, the latter uses a particle swarm optimizer. To reduce the computational complexity further, use of hybrid searches have also been proposed. The test problem construction procedure for the multi-objective bilevel problems have been discussed int his article~\cite{deb2009constructing}. The established NSGA-II is used for solving these problems. The work presented in~\cite{deb2010efficient} combines evolutionary algorithm with a local search, whereas that in~\cite{zhang2013solving} incorporates a crossover operator within a particle swarm optimization. A few different applications have been reported in these papers, including a decision making in a company's scenario~\cite{zhang2013solving,deb2010efficient} and mining~\cite{sinha2013multi}. In ~\cite{sinha2015towards}, a multi-objective version of BLEAQ algorithm, referred to as m-BLEAQ, is applied to solve multi-objective bilevel problems where the lower level decisions are modelled as a value function~(single-objective). In a more recent work~\cite{li2016multiobjective}, the emerging paradigm of decomposition based multi-objective optimization is applied to bilevel problems wherein the lower level problem is single-objective.



\section{Performance Comparison} 
\label{sec:metrics_ch_2}

\subsection{Test Problems}
\label{sec:test}


Two particular sets of problems~(SMD and BLTP) are used most often in the this thesis~(Chapters 3-5) and are therefore noted below. The remaining problems are small in number~(e.g. for multi-follower, applications and multi-objective) and are therefore their formulations are placed in the relevant places within the following chapters themselves.   

\subsubsection{Set 1: SMD problems}

SMD series~\cite{sinha2014test} is a scalable set of test problems which cover a wide range of difficulties associated with bilevel optimization, including non-linearity, multi-modality and conflict in upper and lower level objectives. 
The suite contains twelve problems of which SMD1-SMD8 are unconstrained, whereas the rest are constrained problems. At each level, the problem contains three components, and the overall objective is calculated as the summation of these three components. The generic form of the objective functions is as shown in Equation~\ref{basic_1_ch2}, and the more detailed formulations are given in Appendix A.1.

\begin{equation}
\begin{array}{lr}
 \underset{\mathbf{x}_u}{\text{Minimize}} \hspace{2mm} F_u(\mathbf{x}_u, \mathbf{ x}_l)=$$F_1(\mathbf{x}_{u1})+F_2(\mathbf{x}_{l1}) +F_3(\mathbf{x}_{u2}, \mathbf{x}_{l2})$$\\
 \text{ }\\
\hspace{9mm}\underset{\mathbf{x}_l}{\text{Minimize}}\hspace{2mm} f_l(\mathbf{x}_u, \mathbf{ x}_l)=$$f_1( \mathbf{x}_{u1}, \mathbf{x}_{u2})+f_2(\mathbf{x}_{l1}) +f_3(\mathbf{x}_{u2}, \mathbf{x}_{l2})$$,\\
\hspace{9mm} \text {where}\hspace{2mm}\mathbf{x}_u=( \mathbf{x}_{u1}, \mathbf{x}_{u2}), \hspace{2mm} \text{and} \hspace{2mm} \mathbf{x}_l=( \mathbf{x}_{l1}, \mathbf{x}_{l2})\\
\end{array}
\label{basic_1_ch2}
\end{equation}

Here $F_1$, $F_2$, $F_3$ are the subcomponents of the upper level objective function. Similarly, $f_1$, $f_2$, $f_3$ are treated as subcomponents of the lower level task. The dimension of the variables are set to $|\mathbf{x}_{u1}|=p$, $| \mathbf{x}_{u2}|=r$, $|\mathbf{x}_{l1}|=q$, $| \mathbf{x}_{l2}|=r$. For SMD6, $|\mathbf{x}_{l1}|=q+s$. The value p=1, q=2, r=1 is set for all problems except SMD6 where p=1, q=0, r=1, s=2. These settings correspond to all problems having five variables, two at upper and three at lower level for the studies presented.  The true optimum values for each problem are reported in Table~\ref{BLTP-pro}.

\subsubsection{Set 2: BLTP problems}
\label{test-others}

The second set of thirteen test problems considered here are collected from various references in the literature. The complete mathematical formulations are omitted for the sake of brevity, and could be found in the cited references. The problems are well known in the bilevel optimization domain and have often been used to evaluate the efficacy of different bilevel optimization algorithms. Since a number of these problems have been solved with classical methods, they mostly involve linear and/or quadratic objective and constraint functions. For some of the problems~(BLTP1, BLTP3, BLTP5, BLTP12), the true optimum values are not known, and hence the best considered in the literature are listed. For ease of reference, the problems have been labelled here as BLTP1-BLTP13~(BLTP= Bilevel Test Problems). The source reference for each problem and the optimum values $(F_u^{*},F_l^{*})$ are listed in Table~\ref{BLTP-pro}. More detailed formulations are given in Appendix A.2.

\begin{table}[!ht]\scriptsize
\centering
\caption{Bilevel test problems}
\label{BLTP-pro}
\begin{tabular}{|l|l|l|l|l|}
\hline
\multicolumn{2}{|l|}{Set-1~(\cite{sinha2014test})} & \multicolumn{3}{c|}{Set 2}                 \\ \hline
Problem Name  & $(F_u^{*},F_l^{*})$ & Problem Name & Source & $(F_u^{*},F_l^{*})$       \\ \hline
SMD1          & (0,0)       & BLTP1        &\cite{aiyoshi1984solution}~(Problem 2)       & (0,200)            \\ \hline
SMD2          & (0,0)       & BLTP2        &\cite{bard1988convex}~(Problem 1)            & (17,1)             \\ \hline
SMD3          & (0,0)       & BLTP3        &\cite{Angelobilevel}~(Problem 14)            & (1,0) or~(81.33,0.34)              \\ \hline
SMD4          & (0,0)       & BLTP4        &\cite{oduguwa2002bi}~(F1)                    & (1000,1)           \\ \hline
SMD5          & (0,0)       & BLTP5        &\cite{savard1994steepest}                    & (-1.4074,7.6172)   \\ \hline
SMD6          & (0,0)       & BLTP6        &\cite{bard1988convex}~(Problem 3)            & (100,0)            \\ \hline
SMD7          & (0,0)       & BLTP7        &\cite{anandalingam1990solution}              & (49,-17)           \\ \hline
SMD8          & (0,0)       & BLTP8        &\cite{falk1995bilevel}                       & (-1,0)             \\ \hline
SMD9          & (0,0)       & BLTP9        &\cite{rajesh2003tabu}~(Problem 4)            & (85.0909,-50.1818) \\ \hline
SMD10         & (4,3)       & BLTP10       &\cite{rajesh2003tabu}~(Problem 2)            & (5,4)              \\ \hline
SMD11         & (-1,1)      & BLTP11       &\cite{rajesh2003tabu}~(Problem 3)            & (9,0)              \\ \hline
SMD12         & (3,4)       & BLTP12       &\cite{bard1982explicit}~(Problem 2)          & (3.25,4)           \\ \hline
 \multicolumn{2}{|c|}{--}   & BLTP13       &\cite{candler1982linear}                     & (29.2,-3.2)        \\ \hline
\end{tabular}
\end{table}


\subsection{Comparison metrics}
\subsubsection{Single-Objective Bilevel Optimization}
\label{sing_mat}
In order to evaluate and compare the performance of the proposed approach, the following metrics are used for the single-objective bilevel problems. 

\begin{enumerate}
\item Objective values/errors: For the standard~(single-level) optimization problems, usually the performance could be judged by the statistics of the solutions obtained by each algorithm across multiple independent runs. For minimization, the algorithm which shows lower objective values statistically is considered to have better performance. However, this method of comparison does not hold for bilevel problems as an inaccurate optimum at lower level may result in better objective value for upper level than the true optimum. Thus, in order to unambiguously compare the performance, the availability of true optimum is essential. The performance is compared using an error metric, i.e. for upper level $\epsilon_u = |F^*_u-F^{*t}_u|$, where $F_u^*$ is the best value obtained by the algorithm at the end of the run, and $F^{*t}_u$ is the true optimum. Similarly, for the lower level, the $\epsilon_l = |f^*_l-f^{*t}_l|$. Lower values of $\epsilon_u$ and $\epsilon_l$ represent better accuracy. However, for the cases for which the true optimum is not available~(BLTP1, BLTP3, BLTP12), the comparison is done based on the best known objective values available in the literature. 

\item Computational effort: The next challenge lies in comparing the computational effort, as the upper and lower level have different number of function evaluations. This instigates a question about which of them should be compared or limited to specified number for fair comparison. Due to the nested nature, and with different strategies of handling the function evaluations, it is almost always unattainable to terminate the algorithm at the same number of both upper and lower function evaluations. Hence in the numerical experiments in this thesis, some preliminary experiments are done to determine the algorithm settings required to obtain roughly similar number of function evaluations as obtained using the other algorithms. However, as expected, they often end up to be very different, depending on the search paths during different runs. 

It is to be noted that for real life examples, this comparison should also take into account the relative computational complexity involved in evaluating a function at upper and lower levels. If upper level evaluation is computational intensive, then the total time taken will depend heavily on the upper level function evaluations. Same goes for lower level comparisons.

\item Performance profile: Apart from reporting the median accuracy of the algorithms on individual problems, \textit{performance profile}~\cite{dolan2002benchmarking, barbosa2010using} are also used for a visual comparison. The performance profile is a statistical tool for comparing the performance of multiple approaches against a given performance metric for a large set of problems. In a performance profile plot, the horizontal axis~($\tau$) signifies the performance values relative to the best performing algorithm for a problem. The vertical axis~($\rho(\tau)$) signifies the cumulative distribution of the performance. For a given value of $\tau$, it indicates what proportion of problems was an algorithm able to solve within a factor $\tau$ of the best performer. The algorithms could thus be compared based on a given level of performance $\tau$. Additionally, overall performance could also be quantified using the area under the curve ($AUC = \int{\rho(\tau)d\tau}$)  of the profile. The larger the $AUC$, the higher is the efficacy of the algorithm. 
 \end{enumerate}


\subsubsection{Multi-Objective Bilevel Optimization}

For the multi-objecive problems discussed in Chapter 6, \emph{Hypervolume}~(HV) has been used to quantify non-dominated sets obtained using the proposed approach.  



Hypervolume is a commonly used metric in evolutionary multi-objective optimization domain to provide a combined measure of convergence and diversity of a given set of non-dominated solutions. HV is calculated as the union of the dominated regions by each of solutions with respect to a reference point $Q$ in the objective space. A larger hypervolume measure is preferred. In the context of minimization, the dominated volume can be computed using Equation~\ref{eqn:hv}.



\begin{equation}
\begin{array}{lr}
 \hspace{16mm} Hypervolume={\cup a_{i,R}|v_i \in Q}\\
\end{array}
\label{eqn:hv}
\end{equation}

Here, $a_{i,R}$ is the dominated volume with respect to reference point $R$ for the solution $v_i$ in the non-dominated set $Q$.



















